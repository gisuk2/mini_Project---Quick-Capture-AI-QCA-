import os
import json
from dotenv import load_dotenv
from google import genai  # ìµœì‹  google-genai ë¼ì´ë¸ŒëŸ¬ë¦¬
from notion_client import Client

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# 1. API í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
# í™˜ê²½ ë³€ìˆ˜ì— GEMINI_API_KEY, NOTION_TOKEN, NOTION_DB_IDê°€ ì •í™•íˆ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
notion = Client(auth=os.getenv("NOTION_TOKEN"))
db_id = os.getenv("NOTION_DB_ID")

def analyze_text_with_gemini(text):
    """
    ì œë¯¸ë‚˜ì´ë¥¼ ì´ìš©í•´ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ê³  ì •í˜•í™”ëœ JSON ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # í™•ì¸ëœ ê°€ìš© ëª¨ë¸ ì¤‘ ê°€ì¥ ì•ˆì •ì ì¸ ëª¨ë¸ ì„ íƒ
    model_id = "gemini-flash-lite-latest"
    # model_id = "gemini-2.0-flash" 
    
    prompt = f"""
    ë‹¹ì‹ ì€ IT ì „ë¬¸ íë ˆì´í„°ì…ë‹ˆë‹¤. ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.
    ë°˜ë“œì‹œ ìˆœìˆ˜í•œ JSONë§Œ ë°˜í™˜í•˜ê³ , ```json ê³¼ ê°™ì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
    
    ë¶„ì„ í•­ëª©:
    1. category: [AI, ê°œë°œ, ë¹„ì¦ˆë‹ˆìŠ¤, ì¼ë°˜] ì¤‘ í•˜ë‚˜ ì„ íƒ
    2. tags: ê´€ë ¨ í•µì‹¬ í‚¤ì›Œë“œ 3ê°œ (# í¬í•¨)
    3. summary: ì „ì²´ ë‚´ìš©ì„ ê´€í†µí•˜ëŠ” 1~2ë¬¸ì¥ ìš”ì•½
    4. glossary: ì£¼ìš” ìš©ì–´ ì„¤ëª… (ìµœëŒ€ 2ê°œ, 'term'ê³¼ 'definition' í‚¤ í¬í•¨)

    ë¶„ì„í•  í…ìŠ¤íŠ¸:
    {text}
    """
    
    try:
        response = client.models.generate_content(
            model=model_id,
            contents=prompt
        )
        
        # JSON ë¬¸ìì—´ ì •ì œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
        raw_text = response.text.strip()
        clean_json = raw_text.replace("```json", "").replace("```", "").strip()
        
        return json.loads(clean_json)
    
    except Exception as e:
        print(f"âŒ AI ë¶„ì„ ì¤‘ ì—ëŸ¬: {e}")
        return None

def save_to_notion(data):
    """
    ë¶„ì„ëœ ë°ì´í„°ë¥¼ ë…¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤ í˜•ì‹ì— ë§ì¶° ì €ì¥í•©ë‹ˆë‹¤.
    """
    if not data:
        return

    # ìš©ì–´ ì‚¬ì „ ë°ì´í„°ë¥¼ í•œ ì¤„ì”© í¬ë§·íŒ…
    glossary_list = [f"ğŸ“Œ {g['term']}: {g['definition']}" for g in data['glossary']]
    glossary_final = "\n".join(glossary_list)
    
    try:
        notion.pages.create(
            parent={"database_id": db_id},
            properties={
                "ì´ë¦„": {"title": [{"text": {"content": data['summary']}}]},
                "ì¹´í…Œê³ ë¦¬": {"select": {"name": data['category']}},
                "íƒœê·¸": {"multi_select": [{"name": t} for t in data['tags']]},
                "ìš©ì–´ ì„¤ëª…": {"rich_text": [{"text": {"content": glossary_final}}]}
            }
        )
        print("âœ… ë…¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì„±ê³µ!")
    except Exception as e:
        print(f"âŒ ë…¸ì…˜ ì €ì¥ ì¤‘ ì—ëŸ¬: {e}")
        print("íŒ: ë…¸ì…˜ DB ì—´ ì´ë¦„ì´ 'ì´ë¦„', 'ì¹´í…Œê³ ë¦¬', 'íƒœê·¸', 'ìš©ì–´ ì„¤ëª…'ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")

# ë©”ì¸ ì‹¤í–‰ë¶€
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°
    test_memo = """
    ChatGPT ì ‘ê·¼ì„± í™•ëŒ€ì™€ ê´‘ê³  ë„ì… ë°°ê²½. 
    AI ë°œì „ìœ¼ë¡œ ëˆ„êµ¬ë‚˜ ê°œì¸ìš© ìŠˆí¼ ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ì‹œëŒ€ì— ë„ë‹¬. 
    AI ì ‘ê·¼ì„±ì˜ ì°¨ì´ì— ë”°ë¼ ê¸°íšŒ í™•ëŒ€ ë˜ëŠ” ê²©ì°¨ ì‹¬í™”ê°€ ë°œìƒí•  ìˆ˜ ìˆìŒ.
    """
    
    print("ğŸ¤– AI ë¶„ì„ ì‹œì‘...")
    analyzed_data = analyze_text_with_gemini(test_memo)
    
    if analyzed_data:
        print("ğŸ“Š ë¶„ì„ ê²°ê³¼:", json.dumps(analyzed_data, indent=2, ensure_ascii=False))
        save_to_notion(analyzed_data)